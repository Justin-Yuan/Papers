# Misc

---

### Action Representations for Learning in Continuous Control

link: [https://sites.google.com/stanford.edu/ar4rl/](https://sites.google.com/stanford.edu/ar4rl/)

Summary

- path optimization
- analytic control + high-level learning ?
- learning control + high-level physical reasoning ?
- "Neural Dynamic Policies for End-to-End Sensorimotor Learning"
    - learn and reason in trajectory space
    - reparameterize actions via dynamical systems
- motion planner (obstacle avoidance) + RL (contact rich skills)
    - motion plannar augmented RL, check if next action size (max norm) passes a threshold, if yes use motion planner else use RL

Papers 

**[Learning Contact-Rich Manipulation Tasks with Stability Guarantees**, Shahbaz Abdul Khader, Hang Yin, Pietro Falco and Danica Kragic](https://drive.google.com/file/d/1kCNi3Av8psvicuWPwXwsrRRfbxM3ZiYm/view?usp=sharing)

**[ReLMoGen: Integrating Reinforcement Learningand Motion Generation for Interactive Navigation,** Fei Xia, Chengshu Li, Roberto Martín-Martín, Alexander Toshev, Or Litany, Silvio Savarese](https://drive.google.com/file/d/1yYQ8-JtOf7ve4XBYqURokoyPeqJwwbnl/view?usp=sharing)

**[Neural Dynamic Policies for End-to-End Sensorimotor Learning**, Shikhar Bahl, Mustafa Mukadam, Abhinav Gupta and Deepak Pathak](https://drive.google.com/file/d/1JLTNtKd1yWAjJ8rxzCO52FJfWOTsDpyb/view?usp=sharing)

**[Motion Planner Augmented Action Spaces for Reinforcement Learning, Jun Yamada, Gautam Salhotra, Youngwoon Lee, Max Pflueger**, Karl Pertsch, Peter Englert, Gaurav S. Sukhatme and Joseph J. Lim](https://drive.google.com/file/d/1QaEBRzAmoQ0qsm3Hejvqy6VqZ5Vr8Oob/view?usp=sharing)

**[Learning Task Space Actions for Bipedal Locomotion**, Helei Duan, Kevin Green, Jeremy Dao, Alan Fern and Jonathan Hurst](https://drive.google.com/file/d/1JScljjyXSpGUVG4PQkixTQLh16TkNQzK/view?usp=sharing)

**[Feedback Control for Category-Level Robotic Manipulation**, Wei Gao and Russ Tedrake](https://drive.google.com/file/d/1uSJD4d_pkGulDxixifNgL3U-ypE1xCy8/view?usp=sharing)

---

### Robust autonomy

link: [https://sites.google.com/view/rss2020robustautonomy/home?authuser=0](https://sites.google.com/view/rss2020robustautonomy/home?authuser=0)

summary 

- adaptive stress testing
- Adaptive Tube Library, adapt safety margin on the fly
- “Provably Safe” in the Wild: Control Barrier Functions on a Vision-Based Quadrotor in an Outdoor Environment”
    - control barrier function (for quadrotors)
- “Control-theoretic Evaluation of Policy in Sequential Decision Making via Data-driven Differential Game“
- “Encoding Defensive Driving with Noncooperative Differential Games”
- ”Multi-Objective POMDPs for Robust Autonomy“
- safety critical systems by Aaron Ames
    - Lyapunov functions for stability and control barrier functions for safety
    - set invariance
    - Lyapunov functions are a subset of barrier functions when set is a point
    - safe multi-robot coordination
    - further can bring learning in the picture
    - could have numerical issues at boundaries of the barrier function

---

### Closing the Academia to Real-World Gap in Service Robotics

link: [https://sites.google.com/cs.washington.edu/rss-2020-service-robots/home](https://sites.google.com/cs.washington.edu/rss-2020-service-robots/home)

youtube link: 

[WS2-8: Closing the Academia to Real-World Gap in Service Robotics](https://www.youtube.com/watch?v=7nx_X9OkSbM)

Summary

- faster technological transfer
- metrics and policies that align academic and industrial interests
- 90% gap
- industry companies have advantages
- HRI for service robot, humans are very noise features
- behaviors matter must as much as pre-perception

---

### Visual Learning and Reasoning for Robotic Manipulation

link: [https://sites.google.com/view/rss20vlrrm](https://sites.google.com/view/rss20vlrrm)

Summary: 

- spatial action maps
    - link: [https://spatial-action-maps.cs.princeton.edu/](https://spatial-action-maps.cs.princeton.edu/)
    - each pixel represents an action at a location
    - additional input state channels
- latent space roadmap
    - allows learning global dynamics
- model-based rl
    - condition model on the goal such that it only captures necessary quantities
    - goal-aware prediction
    - re-distribute model prediction errors
    - trajectory true cost ?
- Can learning from pixels be as efficient as learning from state by Pieter Abbeel
    - contrastive learning: SOTA in computer vision
    - keys encoded with momentum
    - CURL can be used even without rewards, fits for multitask
    - but current CURL contrastive representation do not incorporate temporal structure
    - state-based learning + data augmentation ?
- Fei-Fei Li
    - learning tool use from visual
        - keypoint representation for tool manipulation
        - composite task: multi-stage tool use
    - long-horizon tasks
    - ont-shot visual imitation as neural program induction
    - intelligence merges from active perception and interaction in the world
- Connecting TAMP to the real world by Dieter Fox
    - capable and robust manipulation
        - explicit state estimation → detectors, pose estimators, error propagates
        - implicit state estimation →  instead of estimating all low-level states, only learn things matter to robust control, e.g. use deep learning to infer useful features
        - no state estimation → avoid assumptions for learning objects
    - 6D object pose estimation
    - state estimation via DART++
    - grasping in clutter
        - use pre-trained Mask-RCNN to do instance segmentation
        - generate 3D point cloud → cropped point cloud
        - use GraspNet
        - train a CollisionNet to predict collisions (for occluded part in the scene)
    - provide more guidance to the training compared to a pure RL approach