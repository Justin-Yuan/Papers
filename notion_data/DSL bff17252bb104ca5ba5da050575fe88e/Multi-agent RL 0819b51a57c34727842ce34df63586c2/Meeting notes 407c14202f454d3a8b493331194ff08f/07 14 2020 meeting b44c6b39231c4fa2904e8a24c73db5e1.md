# 07/14/2020 meeting

---

# Bookkeeping

Topic: MARL/offline RL chat 

Time: 2pm - 3pm

Participants: Justin, Jacopo 

---

# Pre-meeting

- decentralized control laws learnt with different reward signals or training curriculum ?
- offline rl
    - [offline rl intro and summary blog](https://www.notion.so/justiny/readings-469b20ef40064016a6f424a52233a119#26048929b9144169b6686a9f36b75087)
    - [Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems](https://www.notion.so/justiny/readings-469b20ef40064016a6f424a52233a119#32fbbb80e27f449296e2a38fbd578338)
- multi-agent RL
- multi-agent communication

---

# Meeting notes

### Multi-agent learning

- use learning as framework to figure out communication in multi-agent system
    - use supervised learning to learn a language ?
    - use rl to learn emergent language ?
    - centralized command, how does it scale to more robots
        - use control law to use local information
        - broadcast or point-to-point information
    - if we have prior knowledge, we can use it
    - how to do it in a distributed way instead of the centralized way and scale it up
    - every robot knows state of others within a normal radius
        - then figure out a global configuration
        - propagation need time and bandwidth, might not be correct by the time it arrives
        - addressed by data-driven methods ?
            - enough data ? use properly ?
- problem has to be motivated ? practical reason for building a system
    - warehousing, delivery, autonomous driving
- multi-robot, computer vision based on AirSim
    - resource allocation, parallelization

### Offline RL

- single agent
    - start collecting data → train in simulation → train on crazyfly robots
    - transfer, robust learning, generalization, etc
- multi-agent
    - additional computational, scaling issues ?
        - use centralized control hub or interacting with communication ?
    - faster learning ?

### Project ideas

- survey on safe control learning
- robotics grasping task
    - has large-scale offline datasets
    - progress is more advanced, has well-defined application
    - google has many algorithms for grasping and real-world data
- RSS workshop
    - Dieter Fox says to optimize research output
- smaller, theoretical projects
    - high-level planning , computer vision with AirSim
    - drone simulator
        - voltages control or track point control
- what's doable right now and what your technique would allow to do
- think of somehtig that cannot be done right now
- be direct and speficifc  on if you want direction advice, mentoring or instructions
    - make sure that kind of interaction with supervisor is clear
- directions lab is missing or want to expand
    - grasping ? → adam
    - ask angela
    - others: control and localization

---

# Post-meeting

### TODOs

- check out AirSim and other drone simulators
- read offline RL literature and make a summary
- find works intersecting deep MARL and control (preferably also with aerial robots)
- check on non-learning methods for multi-robot systems

### Next steps

- figure out long-term goal and direction
- figure out short-term project as minimal and achievable step towards goal