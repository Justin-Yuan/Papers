# 08/19/2020 meeting

---

# Bookkeeping

Topic: New student meeting 

Time: 1:45pm - 2:30pm

Participants: Angela, Justin 

---

# Pre-meeting

- multi-agent RL/blue
    - with good factorization ?
        - QMIX ([https://arxiv.org/pdf/1803.11485.pdf](https://arxiv.org/pdf/1803.11485.pdf))
        - infer as probability graphical model ?
            - e.g. Neural Relational Inference ([https://arxiv.org/pdf/1802.04687.pdf](https://arxiv.org/pdf/1802.04687.pdf))
    - with graph neural net ?
        - e.g. Graph Policy Gradients for Large Scale Robot
        Control ([https://arxiv.org/pdf/1907.03822.pdf](https://arxiv.org/pdf/1907.03822.pdf))
        - e.g. Graph Neural Networks for Decentralized Multi-Robot Path
        Planning ([https://arxiv.org/pdf/1912.06095.pdf](https://arxiv.org/pdf/1912.06095.pdf))
    - transfer learning setting ?
        - efficient sim2real
    - analyzing learning dynamics
        - with game theoretical perspective ?
            - e.g. mechanics of n-player differentiable games ([https://arxiv.org/pdf/1802.05642.pdf](https://arxiv.org/pdf/1802.05642.pdf))
- offline RL
    - Jacopo introduces this to me ðŸ™‚
    - collect data and train offline, key is to constrain state-action distributions
    - also how to learn off-policy efficiently (maybe from different behavior policies)
- safety RL
    - got interested from Angela's recent talk in IFAC ðŸ™‚
    - add causal components ? (causal RL)
    - uncertainty-aware components ?
    - data aggregation approaches ?
        - e.g. DAgger ([https://arxiv.org/pdf/1011.0686.pdf](https://arxiv.org/pdf/1011.0686.pdf))
    - borrow analysis from recent imitation learning works (on regret bounds) ?
        - e.g. divergence minimization perspective ([https://arxiv.org/pdf/1911.02256.pdf](https://arxiv.org/pdf/1911.02256.pdf))
- learning metric with NN + tradition graph-based planning
    - e.g. Plan2vec ([https://arxiv.org/pdf/2005.03648.pdf](https://arxiv.org/pdf/2005.03648.pdf))
- theoretical RL and control
    - still getting started (going through course [http://nanjiang.cs.illinois.edu/cs598/](http://nanjiang.cs.illinois.edu/cs598/))

---

# Meeting notes

### project & thesis

- multi-agent
    - start from problem statement, make it clear what problem it tries to solve
    - should connect with real world application, robotics problems
- transfer learning, sim2real
    - possible ways to extend michael & siqi's works ?
    - connect with meta-learning ?
        - e.g. Model-Based Meta-Reinforcement Learning for Flight with Suspended Payloads ([http://arxiv.org/abs/2004.11345](http://arxiv.org/abs/2004.11345))
    - transfer learning applying to multi-agent problem â†’ to compliment lack of data (offline learning issues) ?
- control & RL
    - bridge/bring more perspective from control community to RL community
    - apply stability and dynamics analysis to RL ?
        - e.g. Safe Model-based Reinforcement Learning with Stability Guarantees ([https://arxiv.org/abs/1705.08551](https://arxiv.org/abs/1705.08551))
        - e.g. Neural Lyapunov Control ([https://arxiv.org/pdf/2005.00611.pdf](https://arxiv.org/pdf/2005.00611.pdf))

### safe learning survey paper

- a well-known journal intends for it
- classifying into different categories, methodologies
- benchmarking algorithms
- get to know the team better

---

# Post-meeting

### TODOs

- meet with michael, siqi and jacopo again for updates & pairing
- keep thinking about project & thesis
- check out and help on safe learning survey
- check out usable environments (pybullet, mujoco)
- study control, theoretical RL

### Next steps

- think about problem statement for multi-agent direction
- think about extensions to michael & siqi's transfer learning works
- think about bridging control & RL