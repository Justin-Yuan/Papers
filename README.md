# Papers
Collection of my reading notes, reference to [summary of ML papers I've read](https://github.com/kweonwooj/papers)
Inspired by [Denny Britz] and [Daniel Seita].

Papers are arranged according to three broad categories and then further numbered on a (1) to (5) scale where a (1) means I have only barely skimmed it, while a (5) means I feel confident that I understand almost everything about the paper. Within a single year, these papers should be organized according to publication date.

#### Questions to guide through reading (Reference: [Guide to Reading Academic Research Papers](https://towardsdatascience.com/guide-to-reading-academic-research-papers-c69c21619de6))

1. What previous research and ideas were cited that this paper is building off of? (often in the **introduction**)
2. Was there reasoning for performing this research, if so what was it? (**introduction**)
3. Clearly list out the objectives of the study
4. Was any equipment/software used? (**methods**)
5. What variables were measured during experimentation? (**methods**)
6. Were any statistical tests used? What were their results? (**methods**/**results**)
7. What are the main findings? (**results**)
8. How do these results fit into the context of other research and their 'field'? (**discussion**)
9. Explain each figure and discuss their significance.
10. Can the results be reproduced and is there any code available?
11. Name the authors, year, and title of the paper!
12. Are any of the authors familiar, do you know their previous work? 
13. What key terms and concepts do I not know and need to look up in a dictionary, textbook, or ask someone?
14. What are your thoughts on the results? Do they seem valid?


Contents:

- [Reinforcement and Imitation Learning](#reinforcement-learning-and-imitation-learning)
    - [2019 Papers](#2019-rlil-papers)
    - [2018 Papers](#2018-rlil-papers)
    - [2017 Papers](#2017-rlil-papers)
    - [2016 Papers](#2016-rlil-papers)
    - [2015 Papers](#2015-rlil-papers)
    - [2014 and Earlier](#2014-and-earlier-rlil-papers)
- [Deep Learning](#deep-learning)
    - [2019 Papers](#2019-dl-papers)
    - [2018 Papers](#2018-dl-papers)
    - [2017 Papers](#2017-dl-papers)
    - [2016 Papers](#2016-dl-papers)
    - [2015 Papers](#2015-dl-papers)
    - [2014 and Earlier](#2014-and-earlier-dl-papers)
- [Miscellaneous](#miscellaneous)
    - [2019 Papers](#2019-misc-papers)
    - [2018 Papers](#2018-misc-papers)
    - [2017 Papers](#2017-misc-papers)
    - [2016 Papers](#2016-misc-papers)
    - [2015 Papers](#2015-misc-papers)
    - [2014 Papers](#2014-misc-papers)
    - [2013 and Earlier](#2013-and-earlier-misc-papers)


# Reinforcement Learning and Imitation Learning

## 2019 RL/IL Papers

- [Off-Policy Deep Reinforcement Learning Without Exploration](https://github.com/DanielTakeshi/Paper_Notes/blob/master/reinforcement_learning/Where_Off-Policy_DeepRL_Fails.md) arXiv (5)
- [Visual Foresight: Model-Based Deep Reinforcement Learning for Vision-Based Robotic Control](https://github.com/DanielTakeshi/Paper_Notes/blob/master/reinforcement_learning/Visual_Foresight_MPC.md), arXiv (4)
- [Residual Reinforcement Learning for Robot Control](https://github.com/DanielTakeshi/Paper_Notes/blob/master/reinforcement_learning/Residual_Reinforcement_Learning_for_Robot_Control.md), ICRA 2019 (3)
- [Large-Scale Study of Curiosity-Driven Learning](https://github.com/DanielTakeshi/Paper_Notes/blob/master/reinforcement_learning/Large-Scale_Study_of_Curiosity-Driven_Learning.md), ICLR 2019 (4)
- [Exploration by Random Network Distillation](https://github.com/DanielTakeshi/Paper_Notes/blob/master/reinforcement_learning/Exploration_by_Random_Network_Distillation.md), ICLR 2019 (4)
- [Automatically Composing Representation Transformations as a Means for Generalization](https://github.com/DanielTakeshi/Paper_Notes/blob/master/reinforcement_learning/Automatically_Composing_Representation_Transformations_as_a_Means_for_Generalization.md), ICLR 2019 (2)
- [Diversity is All You Need: Learning Skills without a Reward Function](https://github.com/DanielTakeshi/Paper_Notes/blob/master/reinforcement_learning/Diversity_is_All_You_Need_Learning_Skills_without_a_Reward_Function.md), ICLR 2019 (4)
- [Multi-task Deep Reinforcement Learning with PopArt](https://github.com/DanielTakeshi/Paper_Notes/blob/master/reinforcement_learning/Multi-task_Deep_Reinforcement_Learning_with_PopArt.md), AAAI 2019 (4)

## 2018 RL/IL Papers

Late-year


# Deep Learning

## 2019 DL Papers


## 2018 DL Papers

- [Stochastic Adversarial Video Prediction](https://github.com/DanielTakeshi/Paper_Notes/blob/master/deep_learning/Stochastic_Adversarial_Video_Prediction.md), arXiv 2018 (3)
- [Learning to Teach With Dynamic Loss Functions](https://github.com/DanielTakeshi/Paper_Notes/blob/master/deep_learning/Learning_to_Teach_With_Dynamic_Loss_Functions.md), NeurIPS 2018 (2)
- [Skill Rating for Generative Models](https://github.com/DanielTakeshi/Paper_Notes/blob/master/deep_learning/Skill_Rating_for_Generative_Models.md), arXiv 2018 (3)
- [Born Again Neural Networks](https://github.com/DanielTakeshi/Paper_Notes/blob/master/deep_learning/Born_Again_Neural_Networks.md), ICML 2018 (5)
- Large Scale Distributed Neural Network Training Through Online Distillation, ICLR 2018 (1)
- [Learning to Teach](https://github.com/DanielTakeshi/Paper_Notes/blob/master/deep_learning/Learning_to_Teach.md), ICLR 2018 (5)
- [Interpretable and Pedagogical Examples](https://github.com/DanielTakeshi/Paper_Notes/blob/master/deep_learning/Interpretable_and_Pedagogical_Examples.md) arXiv 2018 (5)




[1]:https://blog.acolyer.org/about/
[2]:https://github.com/dennybritz/deeplearning-papernotes
