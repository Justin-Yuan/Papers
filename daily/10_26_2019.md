# Topics for the day

Langevin dynamics, Stochastic langevin optimization, mutual informatin estimation, graph networks, RL 

<!-- ***************************************************** -->

# List of works
- [META-LEARNING DEEP ENERGY-BASED MEMORY MODELS](#1)
- [Rethinking Kernel Methods for Node Representation Learning on Graphs](#2)
- [Efficient Graph Generation with Graph Recurrent Attention Networks](#3)
- [Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models](#4)
- [Dynamics-aware Embeddings](#5)
- [DIFFTAICHI: DIFFERENTIABLE PROGRAMMING FOR PHYSICAL SIMULATION](#6)
- [UNDERSTANDING THE LIMITATIONS OF VARIATIONAL MUTUAL INFORMATION ESTIMATORS](#7)
- [If MaxEnt RL is the Answer, What is the Question?](#8)
- [Mutual Information Neural Estimation](#9)
- [A MUTUAL INFORMATION MAXIMIZATION PERSPECTIVE OF LANGUAGE REPRESENTATION LEARNING](#10)

<!-- ***************************************************** -->

# Work summaries

<a name="1"></a> 
META-LEARNING DEEP ENERGY-BASED MEMORY MODELS
<https://arxiv.org/pdf/1910.02720.pdf>

- attractor networks (for associative memory)
    - patterns are stored as attractors of the network dynamics
    - associative retrieval is performed by running the dynamics starting from a query pattern until it converges to an attractor
    - e.g. classical Hopfield network 
- allow using arbitrary neural architecture as an energy model and quickly store patterns in its weights
- build compressed memories and efficient associative retrieval


--- 
<a name="2"></a> 
Rethinking Kernel Methods for Node Representation Learning on Graphs
<https://arxiv.org/pdf/1910.02548.pdf> \
code: <https://github.com/bluer555/KernelGCN>

- graph kernels measure graph similarities
- learn node representations capturing structural informatin in graphs
- complementary to other methids, e.g. GCNs 
- decouple kernel fucntion so it can be learned by node class labels
- novel feature aggregation from kernel smoothing 


--- 
<a name="3"></a> 
Efficient Graph Generation with Graph Recurrent Attention Networks
<https://arxiv.org/pdf/1910.00760.pdf>
code: <https://github.com/lrjconan/GRAN>

- deep generative models of graphs, generates graphs 1 block of nodes and associated edges at a time
- compared to RNN-based graph generative models, e.g. GraphVAE, GraphRNN 
- parameterize output distribution per block with mixture of Bernoulli 
- handle node orderings by marginalizing over a family of canonical orderings


---
<a name="4"></a> 
Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models
<https://arxiv.org/pdf/1805.12114.pdf>
code: <https://github.com/kchua/handful-of-trials>

- model based RL, incorporate uncertainty-aware dynamics models, with sampling-based uncertainty propagation 


--- 
<a name="5"></a>
Dynamics-aware Embeddings
<http://willwhitney.com/assets/papers/Dynamics.aware.Embeddings.pdf>
code: <https://github.com/willwhitney/dynamics-aware-embeddings>

- self-supervised representation learning to improve RL sample efficiency
- a forward prediction objective to learn embeddings of both states and actions


---
<a name="6"></a>
DIFFTAICHI: DIFFERENTIABLE PROGRAMMING FOR PHYSICAL SIMULATION
<https://arxiv.org/pdf/1910.00935.pdf>
code: <https://github.com/yuanming-hu/taichi>

- physical simulations via differential programming 
- **differentiating physical simulators does not always yield useful gradients of the physical system being simulated**
- based on *ChainQueen*'s implementation


---
<a name="7"></a>
UNDERSTANDING THE LIMITATIONS OF VARIATIONAL MUTUAL INFORMATION ESTIMATORS
<https://arxiv.org/pdf/1910.06222.pdf>

- variational approaches to estimate mutual information 
- *MINE* could lead to exponential variance in poor conditions
- lots of current estimators don't satisfy MI's properties
- propose estimator focusing on variance reduction 


---
<a name="8"></a>
If MaxEnt RL is the Answer, What is the Question?
<https://arxiv.org/pdf/1910.01913.pdf>

- probability matching <--> maximum entropy RL 
- MaxEnt RL optimally solve certain classes of control problems (for POMDPs)
- MaxEnt RL equivalent to a two-player game where an adversary chooses the reward function
- domains with uncertainty in the task goal may be especially
well-suited for MaxEnt RL


---
<a name="9"></a>
Mutual Information Neural Estimation
<https://arxiv.org/pdf/1801.04062.pdf>

- estimate mutual information between high dimensional continuous variables
- use *MINE* to implement Informatino Bottleneck 

---
<a name="10"></a>
A MUTUAL INFORMATION MAXIMIZATION PERSPECTIVE OF LANGUAGE REPRESENTATION LEARNING
<https://arxiv.org/pdf/1910.08350.pdf>

- word representation learning maximizes an objective function that is a lower bound on the mutual information between different
parts of a word sequence
- unify classical word embedding models and modern contextual embeddings


