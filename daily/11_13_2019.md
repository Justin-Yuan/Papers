# Topics for the day 

<!-- ***************************************************** -->
# List of works
- [Competitive Gradient Descent](#1)
- [ON MUTUAL INFORMATION MAXIMIZATION FOR REPRESENTATION LEARNING](#2)
- [MAVEN: Multi-Agent Variational Exploration](#3)

<!-- ***************************************************** -->
# Work summaries

<a name="1"></a> 
Competitive Gradient Descent
<https://arxiv.org/pdf/1905.12103.pdf>

- numerical computation of Nash equilibria of competitive two-player games
- natural generalization of gradient descent to the two-player setting where the update is given by the Nash equilibrium of a regularized bilinear local approximation of the underlying game
- avoids oscillatory and divergent behaviors 
- detailed comparison to **optimism** and **consensus** 


--- 
<a name="2"></a> 
ON MUTUAL INFORMATION MAXIMIZATION FOR REPRESENTATION LEARNING
<https://arxiv.org/pdf/1907.13625.pdf>

- unsupervised or self-supervised representation learning train feature extractors by maximizing an estimate of the mutual information (MI) between different views of the data
- their success may strongly depend on the inductive
bias in both the choice of feature extractor architectures and the parametrization of the employed MI estimators
- connection to deep metric learning 


---
<a name="3"></a>
MAVEN: Multi-Agent Variational Exploration
<https://arxiv.org/pdf/1910.07483.pdf>

- focus on QMIX, show that the representational constraints on the joint action-values introduced by QMIX and similar methods lead to provably poor exploration and suboptimality
- MAVEN, combine value and policy-based agents, introduce a latent space for hierarchical control 
- allow it to achieve committed, temporally extended exploration 
- test on SMAC 


