# Visual Semantic Navigation Using Scene Priors 
[link](https://arxiv.org/pdf/1810.06543.pdf)

## Intro 

- simulated agent navigation in household environment, using visual input, semantic target, GNN as scene prior/knowledge graph and RL framework
- AI2-THOR framework, phototrealistic & actionable 

## Modeling 

- Visual Input: ImageNet pretrained ResNet-50 -> 512d feature 
- Semantic Target: FastText -> 512d embedding  
- Knowledge graph: GCN, predefined with **Visual Genome Dataset**
    - initial nodes as concat of visual feature and semantic embedding
    - 3 layes of propagation 
- Action space: with/without **Stop** action 

## Evaluation 

- baselines: Random, A3C 
- proposed: A3C + Scene Priors with GCN 
- metric: Success Rate, Success weighted byPath LEngth (SPL)
- test on: Seen/Unseen scenes, Known/Novel objects 

#### Future Work 

- incorporate long-term memory 
- incorporate higher-order relationships between objects & sceens 