# Topics for the day 

unsupervised representation learning, graph networks, information bottleneck 

<!-- ***************************************************** -->

# List of works
- [Momentum Contrast for Unsupervised Visual Representation Learning](#1)
- [CONSTANT CURVATURE GRAPH CONVOLUTIONAL NETWORKS](#2)
- [Diffusion Improves Graph Learning](#3)
- [Learning Representations in Reinforcement Learning: An Information Bottleneck Approach](#4)

<!-- ***************************************************** -->

# Work summaries

<a name="1"></a> 
Momentum Contrast for Unsupervised Visual Representation Learning
<https://arxiv.org/pdf/1911.05722.pdf>

- constrastive (unsupervised) learning [ref](http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf) as dictionary look-up
- Momentum Contrast (MoCo), build a dynamic dictionary with a queue and a moving-averaged encoder 
- representation learnt by MoCo transfer well to downstream tasks


--- 
<a name="2"></a> 
CONSTANT CURVATURE GRAPH CONVOLUTIONAL NETWORKS
<https://arxiv.org/pdf/1911.05076.pdf>

- representation methods for data in non-Euclidean spacess (hyperbolic or spherical), provide inductive bias (scale-free, hierarchical, cyclical)
- popular GNN limited to Euclidean geometry and associated vector space operations
- propose generalization of GCN to constant curvature spaces
- interpolate smoothly between all geometries of constant curvature
- levergae gyro-barycentric coordinates to generalise center of mass 


--- 
<a name="3"></a> 
Diffusion Improves Graph Learning
<https://arxiv.org/pdf/1911.05485.pdf>

- Graph diffusion convolution (GDC), leverage generalized graph diffusion, e.g. heat kernel & PageRank
- replace message passing with graph diffusion convolution, alleviate problem of noisy and often arbitrarily defined edges in real graphs 
- related to spetral-based models, combine strengths of spatial and spetral methods 
- 


---
<a name="4"></a> 
Learning Representations in Reinforcement Learning: An Information Bottleneck Approach
<https://arxiv.org/pdf/1911.05695.pdf>

- information bottleneck method [ref](https://arxiv.org/pdf/physics/0004057.pdf) for representation learning
- analytically derive the optimal conditional distribution of the representatoion, provide a variational lower bound, then maximize with Stein variational gradient 
- incorporate to A2C and PPO, improve sampling efficiency 
- connect with **MINE** [ref](https://arxiv.org/pdf/1801.04062.pdf)


