# Topics for the day 

object-based representation learning, variational inference and RL 

<!-- ***************************************************** -->

# List of works
- [CONTRASTIVE LEARNING OF STRUCTURED WORLD MODELS](#1)
- [VIREL: A Variational Inference Framework for Reinforcement Learning](#2)

<!-- ***************************************************** -->

# Work summaries

<a name="1"></a> 
CONTRASTIVE LEARNING OF STRUCTURED WORLD MODELS
<https://arxiv.org/pdf/1911.12247.pdf>
code: <https://github.com/tkipf/c-swm>

- world model in terms of objects, relations and hierarchies, learn from raw sensory data is a challenge
-  structure each state embedding as a set of object representations and their relations, modeled by a graph neural network
- learn interpretable object-based representations 
- use C-SWM for model-based planning and RL 

**Intro**
- discriminative approach using contrastive learning, scores real against fake experiences in the form of state-action-state triples from an experience buffer
- model environment transitions with graph neural net, operates on latent abstract representations 
- novel object-level contrastive loss for unsupervised learning of object-based representations 
- novel ranking-based evaluation strategy 

**Method**
- connect to graph embedding method **TransE**, it embeds triplets (subject-relation-object) from knowledge base, defines energy of a triples as $d(F(e_t) + G(r_t), F(o_t))$, where $F,G$ are embedding function and $d$ is distance function, training uses energy-based hinge loss 
- adapt to here, with overall loss
$$
L = d(z_t + T(z_t, a_t), z_{t+1}) + max(0, \gamma - d(\tilde{z}_t, z_{t+1}))
$$
where $z$ is embedding state, $T$ is latent transition model, $\tilde{z}$ is random negative sample from experience buffer 
- CNN-based object extractor (K feature maps in last layer as K object slots/object mask) + MLP-based object encoder --> $z$
- transition model as graph neural net --> $z_t + \Delta z_t$
- multi-object constrastive loss, change energy fucntion to take factorization of abstract state space into account
$$
H = \frac{1}{K}\Sigma_{k=1}^{K}d(z_t^k + T^k(z_t,a_t), z_{t+1}^k)
$$
$$
\tilde{H} = \frac{1}{K}\Sigma_{k=1}^{K}d(\tilde{z}_t^k, z_{t+1}^k)
$$
for positive and negative triples, overall loss
$$
L = H + max(0, \gamma, - \tilde{H})
$$
- measure Hits at Rank 1 (H@1) and Mean Reciprocal Rank (MRR)

**Related work**
- COBRA, learns an action-conditioned transition policy on object representattions from unsupervised object discovery, but does not model interactions between objects, relies on pixel-base loss
- MONet, for iterative object encoding 
- physics as inverse graphics, e.g. <https://arxiv.org/pdf/1905.11169.pdf> 

**Limitations**
- instance disambiguation 
- stochasticity & markov assumptions 


--- 
<a name="2"></a> 
VIREL: A Variational Inference Framework for Reinforcement Learning
<https://arxiv.org/pdf/1811.01132.pdf>


